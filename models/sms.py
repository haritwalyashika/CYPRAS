# -*- coding: utf-8 -*-
"""hybrid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/
"""

#!pip install transformers datasets scikit-learn pandas numpy

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
from transformers import DistilBertTokenizer, DistilBertModel
from torch.optim import AdamW  # Native PyTorch version

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import pandas as pd
import numpy as np
from tqdm import tqdm
import os

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Load the dataset
df = pd.read_csv('/content/Dataset.csv')  

# Extract text (only 'Body' column, as a list of strings)
texts = df['Body'].astype(str).tolist()

binary_features = df.iloc[:, 2:-1].values  
# Extract labels (target)
labels = df['Label'].values  
##convert string labels to integer

# Train-validation split
train_texts, val_texts, X_train_bin, X_val_bin, y_train, y_val = train_test_split(
    texts, binary_features, labels, test_size=0.2, random_state=42)

from transformers import DistilBertTokenizer

# Tokenizer for DistilBERT
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

#from transformers import DistilBertTokenizer
import torch
from torch.utils.data import Dataset

class HybridDataset(Dataset):
    def __init__(self, text_data, binary_data, labels, tokenizer, max_len=256):
        self.text_data = text_data  # List of body texts (strings)
        self.binary_data = binary_data  # List of binary features (numerical)
        self.labels = labels  # Target labels
        self.tokenizer = tokenizer  # DistilBERT tokenizer
        self.max_len = max_len  # Maximum sequence length for padding/truncating

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        # Access the body text and binary features directly by index
        body_text = self.text_data[idx]
        binary_feats = self.binary_data[idx]
        label = self.labels[idx]

        # Tokenize the body text using DistilBERT tokenizer
        encoding = self.tokenizer(
            body_text,
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors='pt'  # Returns a dictionary with tensors
        )

        # Return the tokenized inputs as well as the binary features and label
        return {
            'input_ids': encoding['input_ids'].squeeze(0),  # Remove the batch dimension (size 1)
            'attention_mask': encoding['attention_mask'].squeeze(0),  # Same here
            'binary_feats': torch.tensor(binary_feats, dtype=torch.float32),  # Convert binary features to tensor
            'labels': torch.tensor(label, dtype=torch.long)  # Convert label to tensor
        }
print(X_train_bin.shape)  # Should be (n_samples, 51)
print(X_val_bin.shape)    # Should be (n_samples, 51)

#3. DataLoaders
# ----------------------------

train_dataset = HybridDataset(train_texts, X_train_bin, y_train, tokenizer)
val_dataset = HybridDataset(val_texts, X_val_bin, y_val, tokenizer)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)

import torch
import torch.nn as nn
import torch.nn.functional as F

class AttentionPooling(nn.Module):
    def __init__(self, hidden_size):
        super(AttentionPooling, self).__init__()
        self.attention = nn.Linear(hidden_size, 1)

    def forward(self, hidden_states, mask):
        # hidden_states: [batch_size, seq_len, hidden_size]
        # mask: [batch_size, seq_len]

        # Compute raw attention scores
        scores = self.attention(hidden_states).squeeze(-1)  # shape: (batch_size, seq_len)

        # Mask padding tokens by setting their scores to -inf
        scores = scores.masked_fill(mask == 0, -1e9)

        # Normalize with softmax
        weights = F.softmax(scores, dim=1)  # shape: (batch_size, seq_len)

        # Weighted sum of hidden states
        weighted_output = torch.bmm(weights.unsqueeze(1), hidden_states)  # shape: (batch_size, 1, hidden_size)
        return weighted_output.squeeze(1)  # shape: (batch_size, hidden_size)

# Define the model class (reuse this if already defined earlier)


class HybridBERTClassifier(nn.Module):
    def __init__(self, binary_input_size):
        super(HybridBERTClassifier, self).__init__()
        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')
        self.bert_dropout = nn.Dropout(0.3)
        self.binary_net = nn.Sequential(
            nn.Linear(binary_input_size, 32),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        self.classifier = nn.Sequential(
            nn.Linear(768 + 32, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 2)
        )

    def forward(self, input_ids, attention_mask, binary_feats):
        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = bert_output.last_hidden_state  # [batch, seq_len, hidden_size]

        pooled_output = self.attn_pool(hidden_states, attention_mask)  # Apply attention pooling
        pooled_output = self.bert_dropout(pooled_output)

        binary_out = self.binary_net(binary_feats)
        combined = torch.cat((pooled_output, binary_out), dim=1)
        logits = self.classifier(combined)
        return logits

model = HybridBERTClassifier(binary_input_size=51).to(device)
optimizer = AdamW(model.parameters(), lr=2e-5)
loss_fn = nn.CrossEntropyLoss()

history = {'train_loss': [], 'val_loss': []}
os.makedirs("model_outputs", exist_ok=True)

for epoch in range(3):  # Set number of epochs
    model.train()
    train_loss = 0

    for batch in tqdm(train_loader, desc=f"Epoch {epoch+1} Training"):
        # Correct unpacking of the batch
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        binary_feats = batch['binary_feats'].to(device)
        labels = batch['labels'].to(device)

        optimizer.zero_grad()

        # Forward pass
        outputs = model(input_ids, attention_mask, binary_feats)

        # Compute loss
        loss = loss_fn(outputs, labels)

        # Backward pass
        loss.backward()
        optimizer.step()

        # Accumulate loss for the current batch
        train_loss += loss.item()

    # Calculate average training loss for the epoch
    avg_train_loss = train_loss / len(train_loader)
    history['train_loss'].append(avg_train_loss)

    # Validation phase
    model.eval()
    val_loss = 0
    val_preds, val_labels, val_probs = [], [], []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc=f"Epoch {epoch+1} Validation"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            binary_feats = batch['binary_feats'].to(device)
            labels = batch['labels'].to(device)

            # Forward pass
            outputs = model(input_ids, attention_mask, binary_feats)

            # Compute loss
            loss = loss_fn(outputs, labels)
            val_loss += loss.item()

            # Get probabilities and predictions
            probs = F.softmax(outputs, dim=1)[:, 1]  # Probabilities for class 1 (scam)
            preds = torch.argmax(outputs, dim=1)

            val_probs.extend(probs.cpu().numpy())
            val_preds.extend(preds.cpu().numpy())
            val_labels.extend(labels.cpu().numpy())

    # Calculate average validation loss
    avg_val_loss = val_loss / len(val_loader)
    history['val_loss'].append(avg_val_loss)

    print(f"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")

# Loss history
pd.DataFrame(history).to_csv("model_outputs/loss_history.csv", index=False)

# Predictions and labels
np.save("model_outputs/val_predictions.npy", val_preds)
np.save("model_outputs/val_true.npy", val_labels)
np.save("model_outputs/val_probs.npy", val_probs)

# Final Metrics
acc = accuracy_score(val_labels, val_preds)
prec = precision_score(val_labels, val_preds)
rec = recall_score(val_labels, val_preds)
f1 = f1_score(val_labels, val_preds)

with open("model_outputs/metrics.txt", "w") as f:
    f.write(f"Accuracy: {acc:.4f}\n")
    f.write(f"Precision: {prec:.4f}\n")
    f.write(f"Recall: {rec:.4f}\n")
    f.write(f"F1 Score: {f1:.4f}\n")

import pandas as pd

loss_history = pd.read_csv("model_outputs/loss_history.csv")
print(loss_history.columns)

import pandas as pd
import matplotlib.pyplot as plt

# Load loss history
# Plot using DataFrame index as epochs
plt.figure(figsize=(8, 5))
plt.plot(loss_history.index, loss_history['train_loss'], label='Train Loss', marker='o')
plt.plot(loss_history.index, loss_history['val_loss'], label='Validation Loss', marker='o')
plt.title("Loss over Epochs")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("model_outputs/loss_curve.png")
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import (
    confusion_matrix,
    ConfusionMatrixDisplay,
    roc_curve,
    roc_auc_score,
    precision_recall_curve,
    average_precision_score,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)
import os

# Create output directory if it doesn't exist
os.makedirs("model_outputs", exist_ok=True)

# Load data
val_preds = np.load("model_outputs/val_predictions.npy")
val_labels = np.load("model_outputs/val_true.npy")
val_probs = np.load("model_outputs/val_probs.npy")

# --- Metrics ---
acc = accuracy_score(val_labels, val_preds)
prec = precision_score(val_labels, val_preds)
rec = recall_score(val_labels, val_preds)
f1 = f1_score(val_labels, val_preds)
auc = roc_auc_score(val_labels, val_probs)
ap = average_precision_score(val_labels, val_probs)

# Save metrics to text file
with open("model_outputs/metrics.txt", "w") as f:
    f.write(f"Accuracy:  {acc:.4f}\n")
    f.write(f"Precision: {prec:.4f}\n")
    f.write(f"Recall:    {rec:.4f}\n")
    f.write(f"F1 Score:  {f1:.4f}\n")
    f.write(f"ROC AUC:   {auc:.4f}\n")
    f.write(f"Avg Precision: {ap:.4f}\n")

# --- Confusion Matrix ---
cm = confusion_matrix(val_labels, val_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Ham", "Scam"])
fig_cm, ax_cm = plt.subplots(figsize=(5, 5))
disp.plot(ax=ax_cm, cmap=plt.cm.Blues, colorbar=False)
plt.title("Confusion Matrix")
plt.savefig("model_outputs/confusion_matrix.png")
plt.show()

# --- ROC Curve ---
fpr, tpr, _ = roc_curve(val_labels, val_probs)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {auc:.4f}")
plt.plot([0, 1], [0, 1], 'k--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.savefig("model_outputs/roc_curve.png")
plt.show()



# --- Loss Curve (if available) ---
loss_path = "model_outputs/loss_history.csv"
if os.path.exists(loss_path):
    loss_history = pd.read_csv(loss_path)
    plt.figure(figsize=(8, 5))
    plt.plot(loss_history.index, loss_history['train_loss'], label='Train Loss', marker='o')
    plt.plot(loss_history.index, loss_history['val_loss'], label='Validation Loss', marker='o')
    plt.title("Loss over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("model_outputs/loss_curve.png")
    plt.show()

print("All plots saved ")

